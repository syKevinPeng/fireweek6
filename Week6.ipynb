{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 -- Preparing Dataset and Writing an Face Recognition Preprocessor #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conda install tensorflow\\\n",
    "conda install jupyterlab\\\n",
    "conda install pip\\\n",
    "conda install opencv\\\n",
    "conda install matplotlib\\\n",
    "pip install requests\\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset - face recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset link: http://vis-www.cs.umass.edu/lfw/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information:\n",
    "13233 images\n",
    "5749 people\n",
    "1680 people with two or more images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "finish importing!\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# import packages\n",
    "import requests\n",
    "import tarfile\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from typing import List\n",
    "print(\"finish importing!\")\n",
    "\n",
    "# global variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# install dataset\n",
    "# note: it could take more than 5 minute to download. If the circle on the upper right of this window is black, DO NOT stop this process untill see\n",
    "# the output \"Downloading finish\"\n",
    "data_url = \"http://vis-www.cs.umass.edu/lfw/lfw.tgz\"\n",
    "training_pairs_url = \"http://vis-www.cs.umass.edu/lfw/pairsDevTrain.txt\"\n",
    "testing_pairs_url = \"http://vis-www.cs.umass.edu/lfw/pairsDevTest.txt\"\n",
    "anchor_lib_url = \"https://raw.github.com/tensorflow/models/blob/master/research/object_detection/anchor_generators/grid_anchor_generator.py\"\n",
    "zip_dataset_name = \"lfw.tgz\"\n",
    "training_pairs_name = \"pairsDevTrain.txt\"\n",
    "testing_pairs_name = \"pairsDevTest.txt\"\n",
    "data_dir_name = 'data'\n",
    "if not os.path.isdir(data_dir_name):\n",
    "    os.mkdir(data_dir_name)\n",
    "    print(\"Downloading start\")\n",
    "    r = requests.get(data_url,stream = True)\n",
    "    with open(os.path.join(data_dir_name, zip_dataset_name), 'wb') as f:\n",
    "        f.write(r.raw.read())\n",
    "    print(\"Downloading finish\")\n",
    "# download pairsDevTrain.txt and parisDevTest.txt\n",
    "if not os.path.isfile(training_pairs_name):\n",
    "    r = requests.get(training_pairs_url)\n",
    "    with open(training_pairs_name, \"wb\") as file:\n",
    "        file.write(r.content)\n",
    "    print(f\"{training_pairs_name} Downloaded\")\n",
    "if not os.path.isfile(testing_pairs_name):\n",
    "    r = requests.get(testing_pairs_url)\n",
    "    with open(testing_pairs_name, \"wb\") as file:\n",
    "        file.write(r.content)\n",
    "    print(f\"{testing_pairs_name} Downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "finish extracting\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#unzip the package\n",
    "if not len([os.listdir('data')]) > 5700:\n",
    "    tar = tarfile.open(\"data/lfw.tgz\", \"r\")\n",
    "    tar.extractall(data_dir_name)\n",
    "    tar.close\n",
    "    print(\"finish extracting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please read closely to the README before going foreward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# http://vis-www.cs.umass.edu/lfw/README.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# this function return the path to the image with name NAME_ID.jpg\n",
    "def construct_dir_from_name(name, id):\n",
    "    path_name = os.path.join(data_dir_name,\"lfw\",name)\n",
    "    return os.path.join(path_name,name) + \"_\" + f\"{id}\".zfill(4) + \".jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    def __init__(self, txt_file_name, batch_size, anchor_shape = (96,96), channel = 3, shuffle = True):\n",
    "        print(\"initializaing\")\n",
    "        self.batch_size = batch_size\n",
    "        self.anchor_shape = anchor_shape\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        self.txt_file_name = txt_file_name\n",
    "        self.anchar_arr = []\n",
    "        self.channel = channel\n",
    "        self.negative_dir_arr:List[str] = []\n",
    "        self.positive_dir_arr:List[str] = []\n",
    "        \n",
    "        with open(txt_file_name) as f:\n",
    "            for line in f:\n",
    "                line = line.split()\n",
    "                if len(line) == 3:\n",
    "                    self.positive_dir_arr.append([construct_dir_from_name(line[0],line[1]), construct_dir_from_name(line[0], line[2])])\n",
    "                elif len(line) == 4:\n",
    "                    self.negative_dir_arr.append([construct_dir_from_name(line[0],line[1]),construct_dir_from_name(line[2], line[3])])\n",
    "\n",
    "        \n",
    "    # if self.shuffle == true, shuffle the positive and negative indexes\n",
    "    def on_epoch_end(self):\n",
    "        # udpate indexs after each epoch\n",
    "        self.pos_indexes = np.array(len(self.positive_dir_arr))\n",
    "        self.neg_indexes = np.array(len(self.negative_dir_arr))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.pos_indexes)\n",
    "            np.random.shuffle(self.neg_indexes)\n",
    "        print(\"shuffling\")\n",
    "\n",
    "    def __len__(self):\n",
    "        # Denotes the number of batches per epoch\n",
    "        return int(np.floor(len(self.pos_indexes) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        pos_indexes = self.pos_indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        neg_indexes = self.neg_indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        \n",
    "        pos_list_temp = [self.positive_dir_arr[i] for i in pos_indexes]\n",
    "        neg_list_temp = [self.negative_dir_arr[k] for k in neg_indexes]\n",
    "        \n",
    "        anchor_batch, pos_batch, neg_batch = self.__data_generation(pos_list_temp,neg_list_temp)\n",
    "    \n",
    "    def __data_generation(self, pos_index_temp, neg_index_temp):\n",
    "        # construct positive image (numpy) array\n",
    "        pos_img_arr = []\n",
    "        neg_img_arr = []\n",
    "        anchor_arr = [] # todo\n",
    "        for dir in pos_index_temp:\n",
    "            img = cv2.imread(dir[1])\n",
    "            resized_img = cv2.resize(img, self.anchor_shape)\n",
    "            pos_img_arr.append(resized_img)\n",
    "        for dir in neg_index_temp:\n",
    "            img = cv2.imread(dir[0])\n",
    "            resized_img = cv2.resize(img, self.anchor_shape)\n",
    "            neg_img_arr.append(resized_img)\n",
    "        return anchor_arr, pos_img_arr, neg_img_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "initializaing\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-3caddbe3fd67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# for testing only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt_file_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_pairs_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#pos_img_arr, neg_img_arr = data_generator.__d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#img_arr = np.asarray(pos_img_arr)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-2ded4c64bf48>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, txt_file_name, batch_size, anchor_shape, channel, shuffle)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manchor_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manchor_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtxt_file_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtxt_file_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manchar_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-2ded4c64bf48>\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# udpate indexs after each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_indexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositive_dir_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg_indexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnegative_dir_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataGenerator' object has no attribute 'positive_dir_arr'"
     ],
     "ename": "AttributeError",
     "evalue": "'DataGenerator' object has no attribute 'positive_dir_arr'",
     "output_type": "error"
    }
   ],
   "source": [
    "# for testing only\n",
    "data_generator = DataGenerator(txt_file_name=training_pairs_name, batch_size = 2);\n",
    "print(dir(data_generator))\n",
    "#pos_img_arr, neg_img_arr = data_generator.__d\n",
    "#img_arr = np.asarray(pos_img_arr)\n",
    "print(\"shape: \" + str(img_arr.shape))\n",
    "print(\"shape: \" + str(img_arr[0].shape))\n",
    "\n",
    "print(\"testing complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(img_arr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}